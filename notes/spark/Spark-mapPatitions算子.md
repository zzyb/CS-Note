## 	RDD算子-mapPartitions

Spark mapPartitions-与map（）转换类似，但是在这种情况下，函数在RDD的**每个分区（块）上分别运行**，这与map（）在分区的每个元素上运行不同。因此，当您寻找**性能提升时**（调用函数一次/分区而不是一次/元素），mapPartitions也很有用。

- 假设您有1到100个元素分布在10个分区中，即10个元素/分区。map（）转换将调用*func* 100次以处理这100个元素，但是在mapPartitions（）的情况下，*func*将被调用一次/分区，即10次。
- 其次，mapPartitions（）**将数据保存在内存中，即它将结果存储在内存中，直到处理完分区的所有元素为止**。--<u>有OOM的风险</u>
- mapPartitions（）仅在完成整个分区的处理后才返回结果。
- 与map（）转换不同，mapPartitions（）需要迭代器输入。

什么是迭代器？迭代器是一种访问元素集合的方法，它在某些方面类似于List（），Array（）等元素的集合，但区别在于迭代器不会在记忆在一起。相反，迭代器一个接一个地加载元素。在Scala中，您可以使用*hasNext*和*Next*操作访问这些元素。

