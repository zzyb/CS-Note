hdfs是什么：
hdfs全称：
hdfs核心思想：
hdfs的设计思路：
hdfs的架构是什么：
hdfs有哪些程序、作用是什么：
hdfs的优点：
hdfs的缺点：
单点故障是什么：
如何解决单点故障：
----------MapReduce----------
mapreduce的基本流程：
mapreduce程序的第一阶段任务个数由什么决定：
如果存在大文件，按照什么标准切分大文件：
切分策略为128M，如果有200个130大小的文件，将会启动多少个maptask：
如何解决文件切分之后的断行问题：
combiner局部聚合的作用：
combiner局部聚合的本质：
combiner不适合的场景：
mapreduce的默认排序规则：（按照什么、如果是string、如果是int）
mapreduce的map、shuffer、reduce阶段包含：
map阶段--->
    读数据---文件切分---启动多个maptask任务---
    处理数据---
    写数据到磁盘---数据预聚合---数据压缩---
map阶段--->
    拷贝数据到reuduce阶段
reduce阶段--->
    接收来自map阶段的数据---数据量少会写入内存中，超过阈值会写入磁盘中---最终落地为磁盘文件
    内存中存在这合并、内存到磁盘中也在排序（归并排序）
mapreduce的分区与分组有什么不同：
----------YARN----------
