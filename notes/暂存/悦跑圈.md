# 悦跑圈-5.2.1版本_张琰博

## 公司情况

### 地址

广东省**广州**市**天河区**元岗路**智汇park创意产业园**创意办公（独栋）2号 (邮编：510000)

### 规模

200人左右

#### 大数据项目组：

​	人数：15人

​	人员：产品经理、项目经理、开发人员（数据采集组、数据清洗组、数据融合组、数据挖掘组、数据可视化组）

### 薪资待遇

实习工资8000

基本工资7000+1000（住房补贴+餐补）

没有5险1金

### 集群规模

#### **用户量**：

​	用户数超过千万「6300W」，日活跃用户50W

#### **服务器**：

​	集群规模---20台（大数据「13台」+业务系统+数据库系统）

​	内存---32核64G

​	硬盘---16T（16个1T硬盘）「存储数据使用50%容量」

#### **集群规划：**

##### 	**说明：**

​		最近6个月的数据直接文本文件存储。（180天* 15G * 3个副本）「8T 左右」

​		超过6个月的数据压缩存储。（9个半年 * 180天 * 15G *  60 %压缩率  * 3个副本）「45T 左右」

​		总数据量：55-60T（60T/8T约等于8）「数据存储8个服务器上」

##### 	**zookeeper：**3个节点（单独）

##### 	**hdfs：**10个节点

​		datanode：8个节点

​		namenode：2个节点（单独）

##### 	**任务个数：**

​		项目周期：8个月；（8*30=240天=35周）

​		工作时间：35周*5天=175天

​		撸代码天数：175天*60%=100天「每天2-3个小任务开发」

​		最终运行300-400个任务（每个任务跑3分钟左右）		

​		350个*3分钟=1050分钟「17个小时」

​		yarn将资源抽象成多个队列（假设3个队列），各占集群一部分资源。

​		**最终运行17/3=5个小时任务**

### 数据介绍：

#### 数据字段：

| 用户id | 设备 | 手机号 | 注册时间 | 来源渠道 | 浏览行为（uv、pv、time） | 操作行为（跑步、学习、课程分享、邀请等） | 登陆行为（活跃天数、启动次数、使用时长） | 用户画像（性别、年龄、地域、职业、教育水平、兴趣爱好、运动偏好等） |      |
| ------ | ---- | ------ | -------- | -------- | ------------------------ | ---------------------------------------- | :--------------------------------------- | ------------------------------------------------------------ | ---- |
|        |      |        |          |          |                          |                                          |                                          |                                                              |      |

| 课程id | 课程性质（付费、免费） | 上线时间 | 课程节数 | 课程分类 | 主讲教练 | 课程成浏览（pv、uv、time） | 课程订阅 | 完课率（按节计算、按全程计算） |      |
| ------ | ---------------------- | -------- | -------- | -------- | -------- | -------------------------- | -------- | ------------------------------ | ---- |
|        |                        |          |          |          |          |                            |          |                                |      |

#### **数据详情**：

​	日活用户：500000（50w）

​	数据条数：15000000-20000000（1500-2000万条）

​	每日数据量：15-20G（每条数据1kb左右）

​	数据字段：60个（见上表）

##### 	数据存放：

​		清洗之前存放：   存放在HDFS上。

​		清洗之后数据大小：12-16G（清洗掉20%）

​		清洗之后存放：HDFS上。

#### 数据相关问题：

##### 	日活用户如何统计出来的？

​	用户使用时长大于等于所有用户平均使用时长，视为日活用户。

##### 	业务规则：如何判断一个用户多久不登陆，以后就不登陆了？

​	对于新增的注册用户，一周内不再登陆视为流失用户；

​	对于活跃用户，2周不登陆视为流失用户。

##### 	数据从哪来？

​		app客户端埋点，采集数据。发送数据到服务器生成日志文件。

##### 	几个数据源？

​	一个数据库提取的中的静态的用户个人信息、一个动态的app采集得到的的用户行为日志。

## 项目介绍

### 悦跑圈用户分析（离线项目）

#### 	项目介绍：

​	该项目主要针对悦跑圈用户下载、注册、使用进行统计分析，通过对app客户端进行数据埋点采集用户下载渠道、注册信息、使用行为等数据，分析统计app用户增长及来源、不同渠道活跃用户转化、不同版本使用次数等多项重要指标，为app的广告投放、推广以及app核心模块的完善提供可靠的决策依据。

#### 项目流程：

- ##### 	数据采集------------->flume日志采集

​	对app客户端预先埋点，采集用户使用app客户端过程中产生的日志信息。

- ##### 	数据清洗 ------------->编写MR程序

1. ​	清洗缺失的数据（删除记录、自动填充「均值填充」）

2. ​    清洗不合理数值（例如由于计算bug出现的年龄负数等异常数值）

3. ​    清洗数据并转化为符合要求的形式。（例如字符串转化为某种形式的时间戳）

   清洗之后的数据存储在hdfs上。

- ##### 	数据处理------------->sparkSQL与hive整合

​	**使用spark-sql on hive 处理在hdfs上的数据。（通过spark-sql 使用hive 语句操作hive ,底层运行的还是 spark rdd.）**

1. hive通过建立外部表操作存储在hdfs上的数据。
2. 然后通过spark on hive 来分析处理处理数据。
3. 分析处理之后的数据存储在hive中
4. 将分析结果数据通过sqoop导入到HBase中。（后续使用）

**「什么时候用到了hive、什么时候用到了hbase？」**

数据处理阶段使用了hive语句进行逻辑计算，数据落地阶段存储在hbase中。

#### 	负责的地方：

#### 	相关指标如何计算、规则是什么：

### 用户画像分析模块

#### 	项目介绍：

该项目主要针对悦跑圈用户数据收集分析，通过对用户注册信息和使用app 留下的点击流数据的采集，分析app使用者的性别、年龄、职业、运动喜好、位置信息、消费能力等重要指标，从而更好的掌握用户的基本信息与需求，为后续针对用户个性化推荐健身课程、运动产品提供参考，为App进一步优化、改进提供依据，从而进一步提高用户粘合度。

#### 项目流程：

数据采集（来源）------------->

1. 使用sqoop从**业务系统的数据库**中拉取用户基本信息导入Hive数据库中。
2. 使用flume+Kafka实时的收集外部动态数据。包括用户操作信息、行为数据、app日志信息。将数据报表保存到hdfs上。

数据清洗------------->

​	对于实时收集到hdfs上的动态用户数据，编写mr程序对数据进行清洗，清洗之后加载到hive数据库表中。

数据处理------------->

以spark作为计算引擎，离线进行用户画像。将**数据标签化**。

​	---原始数据

​		ip、用户页面停留、使用功能、浏览记录、购买记录、运动记录、地址信息、使用时间/时段

​	---基础标签（我参与的）

​	年龄、性别、地域、运动喜好、运动程度等

​	---高级标签（数据建模、算法、未参与）

​	消费能力、兴趣爱好、职业

#### 	负责的地方：

#### 	**用户画像标签：**

##### 		**静态标签：**年龄、性别、地域、职业等

##### 		**动态标签：**用户浏览、搜索、社区动态、课程收藏/观看、购买记录等

##### 		**多久更新、更新规则：**

动态标签通过用户数据等不断收集，逐渐完善。

通过对浏览历史、收藏、购买等记录行为设定特定的权重，每周重新对数据处理并整合历史权重得出。





![image-20190911142520138](/Users/zhangyanbo/Library/Application Support/typora-user-images/image-20190911142520138.png)

​		

